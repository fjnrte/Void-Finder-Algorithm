{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc181c16-675f-42f8-a570-f59e6ff76a05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "lvl           = None\n",
    "file_path_Sgm = None\n",
    "file_path_Lvl = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc7199-678f-44ba-a885-20f5cbaf81e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./5___Origins___Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08c627-adf4-4c45-97aa-4537600b5aa0",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd404d75-11ba-43b4-8b8c-6bde5fbb3abb",
   "metadata": {},
   "source": [
    "### Get all 26's and all possible pair elements\n",
    "\n",
    "Since we do this by shifting the cube, we automatically check for any connections over the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791bbb6-1bb8-4685-9c8e-5f8e2e3bd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path_Lvl+\"grid_lvld.pk\", 'rb') as f: grid_lvld = pkl.load(f)\n",
    "size = grid_lvld.shape[0]\n",
    "s_r  = range(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1903b-a99a-401b-9f7a-d671f6c25c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_26 = np.full(grid_lvld.shape, True); grid_pairs = np.full(grid_lvld.shape, True)\n",
    "\n",
    "for offs in offsets:\n",
    "    grid_26    &= ((grid_lvld - shift_cube(grid_lvld, offs)) <  0)\n",
    "    grid_pairs &= ((grid_lvld - shift_cube(grid_lvld, offs)) <= 0)\n",
    "\n",
    "grid_pairs &= ~grid_26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e836e814-e853-4f0c-9ab3-319559cdedb0",
   "metadata": {},
   "source": [
    "### Make a list of 26's (isolated origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a686c0be-b258-468c-a968-4f9caedc5d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_origins_isolated = {val: [] for val in range(0, lvl)}\n",
    "\n",
    "for isolated_i in np.argwhere(grid_26):\n",
    "    dict_origins_isolated[grid_lvld[tuple(isolated_i)]].append(isolated_i.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e7803-2ef6-471f-b220-760e065a4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path_Lvl+\"dict_origins_isolated.pk\", 'wb') as f: pkl.dump(dict_origins_isolated, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e516fd-649d-44af-83a2-f22db9f4df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "del grid_26, dict_origins_isolated; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d5d2a-ae58-4f12-b025-a86ba61c1f0b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce06ae7-e4ce-433c-b519-005e24d18091",
   "metadata": {},
   "source": [
    "At this point, we cleared the 26's from the pairs.\n",
    "\n",
    "Next, we want to reduce the number of false pairs before a final comprehensive check, as to save computational time.\n",
    "\n",
    "First, we check if a cell in a pair only neighbors one other cell that iself neighbors (and only it) a lower neighbor, thus not being recognized as part of a pair, leaving the previous cell isolated, but labeled as a pair.\n",
    "\n",
    "Then, we give an idex number to each pair origin using the label() function and connect the indices from one side to the other (remember, we found pairs using the shift method, so even if a cell looks isolated on the edge of the cube, it was found as part of a pair if it should've been). Then we do what we must do to only give one index to all the connected pairs.\n",
    "\n",
    "Final check! Make sure if we subtract from each pair origin (at its edges) any of its surrounding (outside) cells, the result is not zero, because it would mean the origin pair has an elements of the same density that cannot be part of an origin, thus the whole pair cannot be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72262925-4d3c-4a3f-8000-ea1afb762198",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6e6d5-7fce-4526-942e-f787dd819936",
   "metadata": {},
   "source": [
    "### Check which pair elements ended up isolated\n",
    "\n",
    "First, we check if a cell in a pair only neighbors one other cell that iself neighbors (and only it) a lower neighbor, thus not being recognized as part of a pair, leaving the previous cell isolated, but labeled as a pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5ed72-4b0d-4401-bd6f-a4839ae4dd40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "empty_pairs = True\n",
    "if np.sum(grid_pairs) != 0:\n",
    "    empty_pairs = False\n",
    "    \n",
    "    grid_pairs_fake = grid_pairs.copy()\n",
    "    \n",
    "    for offs in offsets: grid_pairs_fake &= ~shift_cube(grid_pairs, offs)\n",
    "    \n",
    "    grid_pairs &= ~grid_pairs_fake\n",
    "\n",
    "    if np.sum(grid_pairs) == 0: empty_pairs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80521922-d02d-453d-b039-a479a1de0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del grid_pairs_fake; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108bee9a-0243-499a-b03a-2b67d08a9cce",
   "metadata": {},
   "source": [
    "### Connect the pairs' indices from one side to the other\n",
    "\n",
    "Make a list of indices for each pair using label() and match them from one-side of the grid to another.\n",
    "\n",
    "Remember, we found pairs using the shift method, so even if a cell looks isolated on the edge of the cube, it was found as part of a pair if it should've been."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb11844-cbb1-4b29-a95c-9f02bbdd65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_labels_pairs = True\n",
    "if not empty_pairs:\n",
    "    labeled, num_features = label(grid_pairs, structure=np.full((3, 3, 3), True))\n",
    "    labels_pairs = labeled_pairs(labeled)\n",
    "\n",
    "    if len(labels_pairs) != 0 :\n",
    "        # remove duplicates regardless of order and maintain an increasing in index ordering\n",
    "        labels_pairs = [list(t) for t in {tuple(sorted(i)) for i in labels_pairs}]\n",
    "        empty_labels_pairs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994b152-02b0-4605-8b0c-0abe1d06dfec",
   "metadata": {},
   "source": [
    "### Merge [a,b] and [b,c] into [a,b,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998e62e-50e1-42c2-9107-5aab5b1ee431",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not empty_labels_pairs:\n",
    "    # [a,b]+[c,b]->[a,b,c]\n",
    "    labels_pairs = combine_lists(labels_pairs)\n",
    "\n",
    "    # [a,b,c]->[a]\n",
    "    abc_a(np.array([len(i) for i in labels_pairs]), \n",
    "          np.array([coord for sublist in labels_pairs for coord in sublist]), \n",
    "          labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058551c3-413f-4f7d-9208-9674518e6647",
   "metadata": {},
   "source": [
    "### Check the pairs' neighbors\n",
    "\n",
    "Final check! Make sure if we subtract from each pair origin (at its edges) any of its surrounding (outside) cells, the result is not zero, because it would mean the origin pair has an elements of the same density that cannot be part of an origin, thus the whole pair cannot be.\n",
    "\n",
    "(We could have just had this check alone, but with the previous ones we saved a lot of computational time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2667aad-771c-42e9-a3a4-25e72228e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not empty_pairs:\n",
    "    grid_fft_max         = np.max(grid_lvld)\n",
    "    grid_to_subtract     = grid_lvld.copy()\n",
    "    grid_subtracted_from = grid_lvld # No need to copy, since we don't use grid_lvld after this\n",
    "    \n",
    "    grid_to_subtract[     grid_pairs] = -1\n",
    "    grid_subtracted_from[~grid_pairs] = grid_fft_max+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697da594-0eba-42f0-8bbe-ca8d72943973",
   "metadata": {},
   "outputs": [],
   "source": [
    "del grid_pairs; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb7edc-4a3e-4544-8533-19394008c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not empty_pairs:\n",
    "    fake_indices = []\n",
    "    \n",
    "    for offs in offsets:\n",
    "    \n",
    "        # Get the grid of origin pairs equal to their surroundings.\n",
    "        grid_diff = grid_subtracted_from - shift_cube(grid_to_subtract, offs)\n",
    "    \n",
    "        # Get from that grid all the cooresponding labeled values from its grid, take these values only\n",
    "        #     once (using list(set())) in a list and save them as fake indices.\n",
    "        for i in list(set(labeled[grid_diff == 0].tolist())): fake_indices.append(i)\n",
    "    \n",
    "    # set() them and remove them.\n",
    "    fake_indices_into_labeled(np.array(list(set(fake_indices))), labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b29088-7f5d-4386-becb-0bc8b3913a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not empty_pairs: del grid_diff, grid_to_subtract, grid_subtracted_from, fake_indices; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e8580-5c70-4258-96c3-af80ac14c657",
   "metadata": {},
   "source": [
    "### Make the dict of pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce398095-1491-4fa3-8a35-e0a23f75148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_origins_pairs = {val: [] for val in range(0, lvl)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc06c85-0d4b-4de5-9d12-6e716c62cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not empty_pairs:\n",
    "    list_pairs = list_pairs_maker(labeled)\n",
    "\n",
    "    with open(file_path_Lvl+\"grid_lvld.pk\", 'rb') as f: grid_lvld = pkl.load(f)\n",
    "\n",
    "    for pairs_i in list_pairs: dict_origins_pairs[grid_lvld[tuple(pairs_i[0])]].append(pairs_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b107f-20b6-4fcb-807b-73564e013843",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path_Lvl+\"dict_origins_pairs.pk\", 'wb') as f: pkl.dump(dict_origins_pairs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbabe9d0",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
